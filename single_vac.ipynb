{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scanpy.external as sce\n",
    "# from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads the Data\n",
    "sc.settings.verbosity = 3            \n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')\n",
    "\n",
    "adata = sc.read_10x_mtx(\n",
    "    \"temp_asc_vaccines/mcm287_A\",  # the directory with the `.mtx` file\n",
    "    var_names='gene_symbols',                # use gene symbols for the variable names (variables-axis index)\n",
    "    cache=True)\n",
    "adata.var_names_make_unique()\n",
    "sample = 'mcm287_A' #sample name\n",
    "results_file = sample + '_sr.h5ad'  # the file that will store the analysis results\n",
    "adata.var['mt'] = adata.var_names.str.startswith('MT-')  # annotate the group of mitochondrial genes as 'mt'\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "ribo_genes = adata.var_names.str.startswith((\"RPS\",\"RPL\"))\n",
    "\n",
    "#Calculates Percent Ribosomal\n",
    "adata.obs['percent_ribo'] = np.sum(\n",
    "    adata[:, ribo_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1\n",
    "\n",
    "#plots violin plot before filtering\n",
    "sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt','percent_ribo'],\n",
    "             jitter=0.4, multi_panel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets initial cell count, prints it\n",
    "initial_cell_count = adata.n_obs\n",
    "print(f\"Initial number of cells: {initial_cell_count}\")\n",
    "\n",
    "# filter by gene count within cells\n",
    "# sc.pp.filter_cells(adata, min_counts= 4000)\n",
    "\n",
    "#filter out genes that appear in less than 3 cells\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "\n",
    "#filter out cells with more than 150000\n",
    "sc.pp.filter_cells(adata, max_counts = 150000)\n",
    "\n",
    "\n",
    "cell_count = adata.n_obs\n",
    "\n",
    "#filters with at least n genes with count 1\n",
    "adata = adata[adata.obs.n_genes_by_counts > 600, :]\n",
    "\n",
    "filtered_cell_count = adata.n_obs\n",
    "\n",
    "#filters by percent mitochondrial\n",
    "adata = adata[adata.obs.pct_counts_mt < 10, :]\n",
    "\n",
    "filtered_cell_count2 = adata.n_obs\n",
    "\n",
    "cells_filtered_out = cell_count - filtered_cell_count\n",
    "cells_filtered_out2 = filtered_cell_count - filtered_cell_count2\n",
    "\n",
    "#prints out all the filter counts\n",
    "print(f\"Number of cells filtered out in counts filtering: {cells_filtered_out}\")\n",
    "print(f\"Number of cells after counts filtering: {filtered_cell_count}\")\n",
    "print(f\"Number of cells filtered out in mt filtering: {cells_filtered_out2}\")\n",
    "print(f\"Number of cells after mt filtering: {filtered_cell_count2}\")\n",
    "\n",
    "#plots the new violin plot after filtering\n",
    "sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'percent_ribo'],\n",
    "             jitter=0.4, multi_panel=True)\n",
    "\n",
    "#adds biomart annotations\n",
    "annot = sc.queries.biomart_annotations(\n",
    "    \"hsapiens\",\n",
    "    [\"ensembl_gene_id\", \"gene_biotype\"], use_cache = True\n",
    ").set_index('ensembl_gene_id')\n",
    "adata.var['gene_ids'] = adata.var['gene_ids'].astype(str)\n",
    "annot.index = annot.index.astype(str)\n",
    "gene_biotype_dict = annot['gene_biotype'].to_dict()\n",
    "#adds biotype to adata object\n",
    "adata.var['gene_biotype'] = adata.var['gene_ids'].map(gene_biotype_dict)\n",
    "#dict of genes to exclude (in this case, IG genes)\n",
    "genes_to_exclude = ['IG_C_gene', 'IG_C_pseudogene', 'IG_D_gene', 'IG_D_pseudogene', 'IG_J_gene', 'IG_LV_gene', 'IG_pseudogene', 'IG_V_gene', 'IG_V_pseudogene', 'IG_J_pseudogene']  # Replace with your list of genes\n",
    "print(adata)\n",
    "# Create a mask to filter out these genes (mask is genes that aren't in the gene exclusion list)\n",
    "mask = ~adata.var[\"gene_biotype\"].isin(genes_to_exclude)\n",
    "# Create a new AnnData object with the filtered genes\n",
    "adata_filtered = adata.copy()\n",
    "adata_filtered = adata_filtered[:, mask]\n",
    "\n",
    "########\n",
    "#uses the mask to calculate the IG gene expression by summing what isn't in the mask which isn't the list so it sums the list\n",
    "adata.obs['IG_gene_expression'] = adata[:, ~mask].X.sum(axis=1)\n",
    "\n",
    "adata.obs['total_gene_expression'] = adata.X.sum(axis=1)\n",
    "\n",
    "\n",
    "# Calculate the percentage of IG gene expression relative to the total gene expression\n",
    "adata_filtered.obs['IG_gene_percentage'] = (adata.obs['IG_gene_expression'] / adata.obs['total_gene_expression']) * 100\n",
    "adata_filtered.write(sample + '_foritgr.h5ad')\n",
    "\n",
    "\n",
    "########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adata_filtered, target_sum=1e4)\n",
    "sc.pp.log1p(adata_filtered)\n",
    "adata_filtered.raw = adata_filtered\n",
    "# Find highly variable genes\n",
    "#finds and plots highly variable genes\n",
    "sc.pp.highly_variable_genes(adata_filtered, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "\n",
    "#filters the adata to include only the highly variable genes\n",
    "adata_filtered = adata_filtered[:, adata_filtered.var.highly_variable]\n",
    "\n",
    "#regresses out the total counts and mitochondrial counts before doing principal component analysis\n",
    "sc.pp.regress_out(adata_filtered, ['total_counts', 'pct_counts_mt', 'percent_ribo'])\n",
    "\n",
    "#Scales each gene to unit variance and clips values exceeding standard deviation 10.\n",
    "sc.pp.scale(adata_filtered, max_value=10)\n",
    "\n",
    "#performs principal coponent analysis and plots the variance ratio\n",
    "sc.tl.pca(adata_filtered, svd_solver='arpack')\n",
    "sc.pl.pca_variance_ratio(adata_filtered, log=True)\n",
    "\n",
    "#preserves a copy of the adata object\n",
    "copydata = adata_filtered.copy()\n",
    "#calls the standard dimensionality reduction and clustering steps on the adata object \n",
    "# neighbors, UMAP, and leiden (clustering)\n",
    "sc.pp.neighbors(adata_filtered, n_neighbors=10, n_pcs=30)\n",
    "sc.tl.umap(adata_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### leftover scrublet code, use if you want to doublet filter at some point\n",
    "# sc.external.pp.scrublet(adata_filtered)\n",
    "# sc.external.pl.scrublet_score_distribution(adata_filtered)\n",
    "# adata_filtered = (adata_filtered[adata_filtered.obs['predicted_doublet'] == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering resolution should be adjusted to ensure that it matches the elbow plot produced above\n",
    "#cut off should be around the \"elbow\" or corner of the plot where intra-PC variance becomes minimal\n",
    "res = .3\n",
    "sc.tl.leiden(adata_filtered, resolution= res, key_added = \"leiden\")\n",
    "\n",
    "#plots the umap based on both sample and cluster\n",
    "sc.pl.umap(adata_filtered, color = ['leiden'], hspace = 1)\n",
    "\n",
    "\n",
    "adata.obsm['X_umap'] = adata_filtered.obsm['X_umap']\n",
    "\n",
    "# Sum the expression values on the adata object\n",
    "adata.obs['IG_gene_percentage'] = (adata.obs['IG_gene_expression'] / adata.obs['total_gene_expression']) * 100\n",
    "\n",
    "# Plot UMAP and color by the combined expression\n",
    "sc.pl.umap(adata, color=['IG_gene_expression'])\n",
    "\n",
    "# Plot UMAP and color by the percentage of IG gene expression\n",
    "sc.pl.umap(adata, color=['IG_gene_percentage'])\n",
    "\n",
    "\n",
    "# Extract leiden cluster information\n",
    "leiden_clusters = adata_filtered.obs['leiden']\n",
    "cluster_counts = leiden_clusters.value_counts().sort_index()\n",
    "\n",
    "# Get UMAP colors for each cluster\n",
    "umap_colors = adata_filtered.uns['leiden_colors']\n",
    "\n",
    "reformed_counter = len(cluster_counts)\n",
    "umap_colors = umap_colors[0: reformed_counter]\n",
    "\n",
    "# Create a DataFrame for easy handling\n",
    "df = pd.DataFrame({\n",
    "    'Cluster': cluster_counts.index,\n",
    "    'Count': cluster_counts.values,\n",
    "    'Color': umap_colors\n",
    "})\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(df['Cluster'], df['Count'], color=df['Color'])\n",
    "\n",
    "# Adding count values above the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, yval + 0.5, int(yval), ha='center', va='bottom')\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xlabel('Cluster')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Data Count by Leiden Cluster')\n",
    "ax.set_xticks(np.arange(len(df['Cluster'])))\n",
    "ax.set_xticklabels(df['Cluster'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sc.tl.rank_genes_groups(adata_filtered, 'leiden', method='wilcoxon')\n",
    "sc.pl.rank_genes_groups(adata_filtered, n_genes=20, sharey=False)\n",
    "ranks = pd.DataFrame(adata_filtered.uns['rank_genes_groups']['names']).head(50)\n",
    "ranks.to_csv('rank_genes_groups' + sample + '.csv')\n",
    "result = adata_filtered.uns['rank_genes_groups']\n",
    "groups = result['names'].dtype.names\n",
    "scoresgroup = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result[key][group]\n",
    "    for group in groups for key in ['names', 'pvals']}).head(50)\n",
    "scoresgroup.to_csv('scores' + sample + '.csv')\n",
    "del adata_filtered.var['gene_biotype']\n",
    "adata_filtered.write(results_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is extra code left over from a previous project - it takes the data, randomly downsamples it 3 times to 85% of the original size, and then reclusters it all and compares the clusters to see if the data clusters in a similar way. This is essentially a good proxy for the robustness of the clustering, and how variable it can be to small parts of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata1 = sc.pp.subsample(copydata, fraction=.85, random_state=1, copy=True)\n",
    "adata2 = sc.pp.subsample(copydata, fraction=.85, random_state=200, copy=True)\n",
    "adata3 = sc.pp.subsample(copydata, fraction=.85, random_state=373, copy=True)\n",
    "\n",
    "sc.pp.neighbors(adata1, n_neighbors=10, n_pcs=40)\n",
    "sc.tl.umap(adata1)\n",
    "sc.tl.leiden(adata1, resolution= res, key_added = \"leiden\")\n",
    "sc.pl.umap(adata1, color = ['leiden'], hspace = 1, title = \"Downsample 1\")\n",
    "plt.show()\n",
    "\n",
    "sc.pp.neighbors(adata2, n_neighbors=10, n_pcs=40)\n",
    "sc.tl.umap(adata2)\n",
    "sc.tl.leiden(adata2, resolution= res, key_added = \"leiden\")\n",
    "sc.pl.umap(adata2, color = ['leiden'], hspace = 1, title=\"Downsample 2\")\n",
    "plt.show()\n",
    "\n",
    "sc.pp.neighbors(adata3, n_neighbors=10, n_pcs=40)\n",
    "sc.tl.umap(adata3)\n",
    "sc.tl.leiden(adata3, resolution= res, key_added = \"leiden\")\n",
    "sc.pl.umap(adata3, color = ['leiden'], hspace = 1, title=\"Downsample 3\")\n",
    "plt.show()\n",
    "labels1 = adata1.obs['leiden']\n",
    "labels2 = adata2.obs['leiden']\n",
    "cmtx = pd.crosstab(labels2, labels1)\n",
    "ncmtx = cmtx.div(cmtx.sum(axis=1), axis=0)\n",
    "count_greater_than_08 = (ncmtx >= 0.8).sum().sum()\n",
    "max_rows_columns = (ncmtx.shape[0])\n",
    "\n",
    "plt.subplots(figsize=(20,15))\n",
    "ax = sns.heatmap(ncmtx, annot=True)\n",
    "ax.set(xlabel = 'random1', ylabel = 'random2', title = (f\"1 vs 2 Normalized: Number of clusters with >=80% cell congruency: {count_greater_than_08} / {max_rows_columns}\"))\n",
    "plt.show()\n",
    "# plt.subplots(figsize=(20,15))\n",
    "# ax = sns.heatmap(cmtx, annot=True)\n",
    "# ax.set(xlabel = 'random1', ylabel = 'random2', title = \"1 vs 2 Raw\")\n",
    "# plt.show()\n",
    "\n",
    "labels1 = adata1.obs['leiden']\n",
    "labels2 = adata3.obs['leiden']\n",
    "cmtx = pd.crosstab(labels2, labels1)\n",
    "ncmtx = cmtx.div(cmtx.sum(axis=1), axis=0)\n",
    "count_greater_than_08 = (ncmtx >= 0.8).sum().sum()\n",
    "max_rows_columns = (ncmtx.shape[0])\n",
    "plt.subplots(figsize=(20,15))\n",
    "ax = sns.heatmap(ncmtx, annot=True)\n",
    "ax.set(xlabel = 'random1', ylabel = 'random3', title = (f\"1 vs 3 Normalized: Number of clusters with >=80% cell congruency: {count_greater_than_08} / {max_rows_columns}\"))\n",
    "plt.show()\n",
    "# plt.subplots(figsize=(20,15))\n",
    "# ax = sns.heatmap(cmtx, annot=True)\n",
    "# ax.set(xlabel = 'random1', ylabel = 'random3', title = \"1 vs 3 Raw\")\n",
    "# plt.show()\n",
    "\n",
    "labels1 = adata2.obs['leiden']\n",
    "labels2 = adata3.obs['leiden']\n",
    "cmtx = pd.crosstab(labels2, labels1)\n",
    "ncmtx = cmtx.div(cmtx.sum(axis=1), axis=0)\n",
    "count_greater_than_08 = (ncmtx >= 0.8).sum().sum()\n",
    "max_rows_columns = (ncmtx.shape[0])\n",
    "plt.subplots(figsize=(20,15))\n",
    "ax = sns.heatmap(ncmtx, annot=True)\n",
    "ax.set(xlabel = 'random2', ylabel = 'random3', title = (f\"2 vs 3 Normalized: Number of clusters with >=80% cell congruency: {count_greater_than_08} / {max_rows_columns}\"))\n",
    "plt.show()\n",
    "# plt.subplots(figsize=(20,15))\n",
    "# ax = sns.heatmap(cmtx, annot=True)\n",
    "# ax.set(xlabel = 'random2', ylabel = 'random3', title = \"2 vs 3 Raw\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "labels1 = adata_filtered.obs['leiden']\n",
    "labels2 = adata1.obs['leiden']\n",
    "cmtx = pd.crosstab(labels2, labels1)\n",
    "ncmtx1 = cmtx.div(cmtx.sum(axis=1), axis=0)\n",
    "count_greater_than_08 = (ncmtx1 >= 0.8).sum().sum()\n",
    "max_rows_columns = (ncmtx1.shape[0])\n",
    "plt.subplots(figsize=(20,15))\n",
    "ax = sns.heatmap(ncmtx1, annot=True)\n",
    "ax.set(xlabel = 'Full', ylabel = 'random1', title = (f\"1 vs Full Normalized: Number of clusters with >=80% cell congruency: {count_greater_than_08} / {max_rows_columns}\"))\n",
    "plt.show()\n",
    "# plt.subplots(figsize=(20,15))\n",
    "# ax = sns.heatmap(cmtx, annot=True)\n",
    "# ax.set(xlabel = 'Full', ylabel = 'random1', title = \"1 vs Full Raw\")\n",
    "# plt.show()\n",
    "\n",
    "labels1 = adata_filtered.obs['leiden']\n",
    "labels2 = adata2.obs['leiden']\n",
    "cmtx = pd.crosstab(labels2, labels1)\n",
    "ncmtx2 = cmtx.div(cmtx.sum(axis=1), axis=0)\n",
    "count_greater_than_08 = (ncmtx2 >= 0.8).sum().sum()\n",
    "max_rows_columns = (ncmtx2.shape[0])\n",
    "plt.subplots(figsize=(20,15))\n",
    "ax = sns.heatmap(ncmtx2, annot=True)\n",
    "ax.set(xlabel = 'Full', ylabel = 'random2', title = (f\"2 vs Full Normalized: Number of clusters with >=80% cell congruency: {count_greater_than_08} / {max_rows_columns}\"))\n",
    "plt.show()\n",
    "# plt.subplots(figsize=(20,15))\n",
    "# ax = sns.heatmap(cmtx, annot=True)\n",
    "# ax.set(xlabel = 'Full', ylabel = 'random2', title = \"2 vs Full Raw\")\n",
    "# plt.show()\n",
    "\n",
    "labels1 = adata_filtered.obs['leiden']\n",
    "labels2 = adata3.obs['leiden']\n",
    "cmtx = pd.crosstab(labels2, labels1)\n",
    "ncmtx3 = cmtx.div(cmtx.sum(axis=1), axis=0)\n",
    "count_greater_than_08 = (ncmtx3 >= 0.8).sum().sum()\n",
    "max_rows_columns = (ncmtx3.shape[0])\n",
    "#max_rows_columns = max(ncmtx3.shape[0], ncmtx3.shape[1])\n",
    "plt.subplots(figsize=(20,15))\n",
    "ax = sns.heatmap(ncmtx3, annot=True)\n",
    "ax.set(xlabel = 'Full', ylabel = 'random3', title = (f\"3 vs Full Normalized: Number of clusters with >=80% cell congruency: {count_greater_than_08} / {max_rows_columns}\"))\n",
    "plt.show()\n",
    "# plt.subplots(figsize=(20,15))\n",
    "# ax = sns.heatmap(cmtx, annot=True)\n",
    "# ax.set(xlabel = 'Full', ylabel = 'random3', title = \"3 vs Full Raw\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "x = 0\n",
    "ncmtx_list = [ncmtx1, ncmtx2, ncmtx3]\n",
    "data_frames_dict = {}\n",
    "while x <= 2:\n",
    "    # Define the threshold for keeping cells\n",
    "    threshold = 0.8\n",
    "    ncmtx = ncmtx_list[x]\n",
    "\n",
    "    # Identify clusters with scores greater than or equal to 0.8\n",
    "    clusters_above_threshold = ncmtx.columns[ncmtx.max(axis=0) >= threshold]\n",
    "\n",
    "    # Create a DataFrame to store selected clusters and row values\n",
    "    selected_clusters_df = pd.DataFrame(index=ncmtx.index, columns=['Row'] + clusters_above_threshold.tolist())\n",
    "\n",
    "    # Fill the 'Row' column with row values\n",
    "    selected_clusters_df['Row'] = selected_clusters_df.index\n",
    "\n",
    "    # Fill the DataFrame with column labels for rows with scores above the threshold\n",
    "    for cluster in clusters_above_threshold:\n",
    "        selected_clusters_df[cluster] = ncmtx[cluster].apply(lambda x: cluster if x >= threshold else None)\n",
    "\n",
    "    # Melt the DataFrame to have rows first, then columns\n",
    "    selected_clusters_df = selected_clusters_df.melt(id_vars=['Row'], value_vars=clusters_above_threshold, var_name='Cluster')\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    selected_clusters_df = selected_clusters_df.dropna()\n",
    "\n",
    "    # Reset index for the final result\n",
    "    selected_clusters_df.reset_index(drop=True, inplace=True)\n",
    "    selected_clusters_df = selected_clusters_df[['Row', 'Cluster']]\n",
    "\n",
    "    rows_below_threshold = ncmtx.index.difference(selected_clusters_df['Row'])\n",
    "\n",
    "    # Iterate over rows below the threshold and find additional clusters\n",
    "    for row in rows_below_threshold:\n",
    "        # Sort clusters by score in descending order\n",
    "        sorted_clusters = ncmtx.loc[row].sort_values(ascending=False)\n",
    "        \n",
    "        # Find the minimum number of clusters to reach a combined score of at least 0.8\n",
    "        cumulative_sum = 0\n",
    "        min_clusters = []\n",
    "        \n",
    "        for cluster, score in sorted_clusters.items():\n",
    "            cumulative_sum += score\n",
    "            min_clusters.append(cluster)\n",
    "            \n",
    "            if cumulative_sum >= threshold:\n",
    "                break\n",
    "\n",
    "        # Append the row value and selected clusters to the existing DataFrame\n",
    "        additional_clusters_df = pd.DataFrame({'Row': [row], 'Cluster': [min_clusters]})\n",
    "        selected_clusters_df = pd.concat([selected_clusters_df, additional_clusters_df], ignore_index=True)\n",
    "\n",
    "    selected_clusters_df = selected_clusters_df.sort_values(by='Row').reset_index(drop=True)\n",
    "    data_frames_dict[f'iteration{x}'] =  selected_clusters_df\n",
    "    x = x + 1\n",
    "print(\"Selected Clusters and Column Values:\")\n",
    "print(data_frames_dict)\n",
    "\n",
    "\n",
    "df_clusters1 = data_frames_dict['iteration0']\n",
    "df_clusters2 = data_frames_dict['iteration1']\n",
    "df_clusters3 = data_frames_dict['iteration2']\n",
    "\n",
    "# Build mappings for each dataframe\n",
    "cluster_mappings = []\n",
    "for df_clusters in [df_clusters1, df_clusters2, df_clusters3]:\n",
    "    mapping = {}\n",
    "    for index, row in df_clusters.iterrows():\n",
    "        allowed_clusters = row['Cluster']\n",
    "        if not isinstance(allowed_clusters, list):\n",
    "            allowed_clusters = [allowed_clusters]\n",
    "        mapping[row['Row']] = allowed_clusters\n",
    "    cluster_mappings.append(mapping)\n",
    "\n",
    "# Get the cluster labels for each cell in dataset1 and dataset2\n",
    "clusters_dataset1 = adata1.obs['leiden']  # Replace 'leiden' with your actual cluster column name if different\n",
    "clusters_dataset2 = adata2.obs['leiden']  # Replace 'leiden' with your actual cluster column name if different\n",
    "clusters_dataset3 = adata3.obs['leiden']\n",
    "clusters_dataset0 = adata_filtered.obs['leiden']\n",
    "\n",
    "reduced_clusters = {1: clusters_dataset1, 2: clusters_dataset2, 3: clusters_dataset3}\n",
    "# Filter out cells from dataset2 based on the mappings\n",
    "cells_to_keep = []\n",
    "for cell in adata2.obs_names:\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "    x = 1\n",
    "    for mapping in cluster_mappings:\n",
    "        if cell in reduced_clusters[x].index:\n",
    "            total_count += 1\n",
    "            cluster_label_dataset1 = reduced_clusters[x][cell]\n",
    "            cluster_label_root = clusters_dataset0[cell]\n",
    "            if cluster_label_root in mapping.get(cluster_label_dataset1, []):\n",
    "                correct_count += 1\n",
    "        x = x + 1\n",
    "    # Keep the cell if it's correct in at least two dataframes or if it appears in less than two dataframes\n",
    "    if correct_count >= 2 or (total_count < 2 & correct_count == 1):\n",
    "        cells_to_keep.append(cell)\n",
    "\n",
    "# Subset dataset2 to only include cells that are in the list of cells to keep\n",
    "adata0_filtered = adata_filtered[cells_to_keep]\n",
    "\n",
    "sc.pl.umap(adata0_filtered, color = ['leiden'], hspace = 1, title=\"Downsample Cluster-Checked Removal\")\n",
    "\n",
    "adata.obs['keep'] = adata.obs_names.isin(cells_to_keep)\n",
    "\n",
    "# Convert the boolean array to a categorical type for better plotting\n",
    "adata.obs['keep'] = adata.obs['keep'].astype('category')\n",
    "\n",
    "# Plot the UMAP\n",
    "sc.pl.umap(adata, color='keep', palette=['red', 'blue'], title='UMAP of Cells Kept/ Discarded')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scanpy2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
